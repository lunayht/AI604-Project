NOTE: 
    When installing timm (pytorch-image-models), make sure to install from Github source.
    The PyPI version is not up-to-date.


## Classification Training Script

The training script has the following features:
    1. Supports pretrained models
    2. Supports following training options w/ HuggingFace accelerate integration:
        - FP16 (PyTorch native automatic mixed precision)
        - Distributed
    3. Supports wandb logging
    4. Supports validation metrics (Top@5, Top@1 for 8 class classification, Top@1 for binary)

In order to launch distributed training, configure accelerate first then launch:
    $ accelerate config
    $ accelerate launch train.py

## Classification Preprocessing Script

The data has been combined into a single dataset according to their magnification.

The preprocessing pipeline takes the following steps:

    1. BreakHisDataset class takes only file names upon initialization
    2. Upon BreakHisDataset.__getitem__ is called, each image is read 
       as numpy array divided by 255.0.
    3. FeatureExtractor is initialized. This can be configured to do data
       augmentation. By default, it resizes the image to the input size. 
       This is again normalized for ViT.
    4. BatchCollector collects the list of examples (given as List[Dict]),
       which is passed as collate_fn in DataLoader. This creates our 
       torch.Tensor.

## Launching

Since accelerate handles every cases, you can run the script like the following:

CUDA_VISIBLE_DEVICES=${YOUR_GPU} accelerate launch train.py ${--training-args}
